# Text-Summarization-API-using-Large-Language-Models-LLMs

# Project Overview

This project implements a basic-level implementation text summarization API using pre-trained Large Language Models (LLMs) such as BART. It demonstrates the application of Artificial Intelligence (AI) in Natural Language Processing (NLP) and integrates key concepts of Prompt Design and Generative AI, as learned from the Google AI Essentials course, particularly in the areas of Artificial Intelligence (AI), Prompt Design, LLMs, and Generative AI

# Key Concepts Applied:
* Artificial Intelligence (AI): Automates the summarization of human language using pre-trained models.

* Prompt Design: Optimizes input prompts to improve summarization quality.

* Large Language Models (LLMs): Utilizes the BART model for efficient text summarization.

* Generative AI: Automatically generates summaries from long-form text inputs.

# Tools & Technologies:
* Flask: Builds the API to handle user requests.
* Hugging Face Transformers: Provides the pre-trained BART model and tokenizer for summarizing tasks.
* PyTorch: Powers the model inference through its deep learning framework.
* BART Model: A pre-trained text summarization model used for generating concise summaries.
* Ngrok: Exposes the local Flask API to the internet for external access.
* Invoke-WebRequest: A PowerShell command used to send POST requests to the API for testing.
* JSON & HTTP: Communication standards between the API and the client.

# 1. Text Summarization
Using the BART model, this API summarizes long-form content into concise summaries, focusing on extracting key information. The prompt design and model fine-tuning were influenced by the AI techniques learned in the Google AI course.
# 2. Content Generation
By leveraging generative AI models like GPT-2, this project demonstrates how creative text can be automatically generated from prompts, with a focus on creativity and automation. The project aligns with my learning on Generative AI to design a system capable of generating meaningful and coherent content.

# Future Directions
•	Further fine-tuning and experimentation with BERT-like models for question answering.

•	Implementing automated text summarization pipelines using real-time data feeds.

•	Exploring advanced prompt engineering techniques to improve response generation for specific applications like customer support or virtual assistants.

